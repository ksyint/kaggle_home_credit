{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6495922d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:02.336854Z",
     "iopub.status.busy": "2024-05-18T15:42:02.336007Z",
     "iopub.status.idle": "2024-05-18T15:42:08.215369Z",
     "shell.execute_reply": "2024-05-18T15:42:08.214500Z"
    },
    "papermill": {
     "duration": 5.888916,
     "end_time": "2024-05-18T15:42:08.217656",
     "exception": false,
     "start_time": "2024-05-18T15:42:02.328740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d91b486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:08.230139Z",
     "iopub.status.busy": "2024-05-18T15:42:08.229447Z",
     "iopub.status.idle": "2024-05-18T15:42:08.233900Z",
     "shell.execute_reply": "2024-05-18T15:42:08.233092Z"
    },
    "papermill": {
     "duration": 0.012723,
     "end_time": "2024-05-18T15:42:08.235898",
     "exception": false,
     "start_time": "2024-05-18T15:42:08.223175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT            = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\n",
    "TRAIN_DIR       = ROOT / \"parquet_files\" / \"train\"\n",
    "TEST_DIR        = ROOT / \"parquet_files\" / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b68644eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:08.247589Z",
     "iopub.status.busy": "2024-05-18T15:42:08.247267Z",
     "iopub.status.idle": "2024-05-18T15:42:16.721895Z",
     "shell.execute_reply": "2024-05-18T15:42:16.721077Z"
    },
    "papermill": {
     "duration": 8.483174,
     "end_time": "2024-05-18T15:42:16.724220",
     "exception": false,
     "start_time": "2024-05-18T15:42:08.241046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.4.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "state_dict = joblib.load('/kaggle/input/fitted-models/week_num_dict.pkl')\n",
    "cat_cols = state_dict['cat_cols']\n",
    "train_cols = state_dict['train_cols']\n",
    "lgb = state_dict['lgb'][5:]\n",
    "cbc = state_dict['cat'][5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51efec6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:16.736303Z",
     "iopub.status.busy": "2024-05-18T15:42:16.735969Z",
     "iopub.status.idle": "2024-05-18T15:42:16.771488Z",
     "shell.execute_reply": "2024-05-18T15:42:16.770682Z"
    },
    "papermill": {
     "duration": 0.043723,
     "end_time": "2024-05-18T15:42:16.773359",
     "exception": false,
     "start_time": "2024-05-18T15:42:16.729636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "\n",
    "    def set_table_dtypes(df):\n",
    "        for col in df.columns:\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "            elif col in [\"date_decision\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "            elif col[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String))\n",
    "            elif col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "        return df\n",
    "\n",
    "    def handle_dates(df):\n",
    "        for col in df.columns:\n",
    "            if col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))  #!!?\n",
    "                df = df.with_columns(pl.col(col).dt.total_days()) # t - t-1\n",
    "        df = df.drop(\"date_decision\", \"MONTH\")\n",
    "        return df\n",
    "\n",
    "    def filter_cols(df):\n",
    "#         for col in df.columns:\n",
    "#             if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n",
    "#                 isnull = df[col].is_null().mean()\n",
    "#                 if isnull > 0.7:\n",
    "#                     df = df.drop(col)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n",
    "                freq = df[col].n_unique()\n",
    "                if (freq == 1) | (freq > 200):\n",
    "                    df = df.drop(col)\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "class Aggregator:\n",
    "    #Please add or subtract features yourself, be aware that too many features will take up too much space.\n",
    "    def num_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        \n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return expr_max +expr_last+expr_mean\n",
    "    \n",
    "    def date_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"D\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        #expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return  expr_max +expr_last+expr_mean\n",
    "    \n",
    "    def str_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        #expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        #expr_count = [pl.count(col).alias(f\"count_{col}\") for col in cols]\n",
    "        return  expr_max +expr_last#+expr_count\n",
    "    \n",
    "    def other_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        #expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        return  expr_max +expr_last\n",
    "    \n",
    "    def count_expr(df):\n",
    "        cols = [col for col in df.columns if \"num_group\" in col]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols] \n",
    "        #expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        return  expr_max +expr_last\n",
    "    \n",
    "    def get_exprs(df):\n",
    "        exprs = Aggregator.num_expr(df) + \\\n",
    "                Aggregator.date_expr(df) + \\\n",
    "                Aggregator.str_expr(df) + \\\n",
    "                Aggregator.other_expr(df) + \\\n",
    "                Aggregator.count_expr(df)\n",
    "\n",
    "        return exprs\n",
    "\n",
    "def read_file(path, depth=None):\n",
    "    df = pl.read_parquet(path)\n",
    "    df = df.pipe(Pipeline.set_table_dtypes)\n",
    "    if depth in [1,2]:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df)) \n",
    "    return df\n",
    "\n",
    "def read_files(regex_path, depth=None):\n",
    "    chunks = []\n",
    "    \n",
    "    for path in glob(str(regex_path)):\n",
    "        df = pl.read_parquet(path)\n",
    "        df = df.pipe(Pipeline.set_table_dtypes)\n",
    "        if depth in [1, 2]:\n",
    "            df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "        chunks.append(df)\n",
    "    df = pl.concat(chunks, how=\"vertical_relaxed\")\n",
    "    df = df.unique(subset=[\"case_id\"])\n",
    "    return df\n",
    "\n",
    "def feature_eng(df_base, depth_0, depth_1, depth_2):\n",
    "    df_base = (\n",
    "        df_base\n",
    "        .with_columns(\n",
    "            month_decision = pl.col(\"date_decision\").dt.month(),\n",
    "            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n",
    "        )\n",
    "    )\n",
    "    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n",
    "    df_base = df_base.pipe(Pipeline.handle_dates)\n",
    "    return df_base\n",
    "\n",
    "def to_pandas(df_data, cat_cols=None):\n",
    "    df_data = df_data.to_pandas()\n",
    "    if cat_cols is None:\n",
    "        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n",
    "    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n",
    "    return df_data, cat_cols\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if str(col_type)==\"category\":\n",
    "            continue\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            continue\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "056e4f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:16.784401Z",
     "iopub.status.busy": "2024-05-18T15:42:16.784105Z",
     "iopub.status.idle": "2024-05-18T15:42:16.788615Z",
     "shell.execute_reply": "2024-05-18T15:42:16.787777Z"
    },
    "papermill": {
     "duration": 0.012191,
     "end_time": "2024-05-18T15:42:16.790554",
     "exception": false,
     "start_time": "2024-05-18T15:42:16.778363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_store = {\n",
    "#     \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n",
    "#     \"depth_0\": [\n",
    "#         read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n",
    "#         read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n",
    "#     ],\n",
    "#     \"depth_1\": [\n",
    "#         read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n",
    "#         read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n",
    "#         read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n",
    "#         read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n",
    "#         read_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n",
    "#         read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n",
    "#         read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n",
    "#         read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n",
    "#         read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n",
    "#         read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n",
    "#     ],\n",
    "#     \"depth_2\": [\n",
    "#         read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n",
    "#         read_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n",
    "#         read_files(TRAIN_DIR / \"train_person_2.parquet\", 2),\n",
    "#         read_files(TRAIN_DIR / \"train_applprev_2.parquet\", 2),\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7fd5ab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:16.801909Z",
     "iopub.status.busy": "2024-05-18T15:42:16.801647Z",
     "iopub.status.idle": "2024-05-18T15:42:16.806964Z",
     "shell.execute_reply": "2024-05-18T15:42:16.806130Z"
    },
    "papermill": {
     "duration": 0.013201,
     "end_time": "2024-05-18T15:42:16.808854",
     "exception": false,
     "start_time": "2024-05-18T15:42:16.795653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_train = feature_eng(**data_store)\n",
    "# print(\"train data shape:\\t\", df_train.shape)\n",
    "# del data_store\n",
    "# gc.collect()\n",
    "# df_train = df_train.pipe(Pipeline.filter_cols)\n",
    "# df_train, cat_cols = to_pandas(df_train)\n",
    "# df_train = reduce_mem_usage(df_train)\n",
    "# print(\"train data shape:\\t\", df_train.shape)\n",
    "# nums=df_train.select_dtypes(exclude='category').columns\n",
    "# from itertools import combinations, permutations\n",
    "# #df_train=df_train[nums]\n",
    "# nans_df = df_train[nums].isna()\n",
    "# nans_groups={}\n",
    "# for col in nums:\n",
    "#     cur_group = nans_df[col].sum()\n",
    "#     try:\n",
    "#         nans_groups[cur_group].append(col)\n",
    "#     except:\n",
    "#         nans_groups[cur_group]=[col]\n",
    "# del nans_df; x=gc.collect()\n",
    "\n",
    "# def reduce_group(grps):\n",
    "#     use = []\n",
    "#     for g in grps:\n",
    "#         mx = 0; vx = g[0]\n",
    "#         for gg in g:\n",
    "#             n = df_train[gg].nunique()\n",
    "#             if n>mx:\n",
    "#                 mx = n\n",
    "#                 vx = gg\n",
    "#             #print(str(gg)+'-'+str(n),', ',end='')\n",
    "#         use.append(vx)\n",
    "#     return use\n",
    "\n",
    "# def group_columns_by_correlation(matrix, threshold=0.8):\n",
    "#     # 计算列之间的相关性\n",
    "#     correlation_matrix = matrix.corr()\n",
    "\n",
    "#     # 分组列\n",
    "#     groups = []\n",
    "#     remaining_cols = list(matrix.columns)\n",
    "#     while remaining_cols:\n",
    "#         col = remaining_cols.pop(0)\n",
    "#         group = [col]\n",
    "#         correlated_cols = [col]\n",
    "#         for c in remaining_cols:\n",
    "#             if correlation_matrix.loc[col, c] >= threshold:\n",
    "#                 group.append(c)\n",
    "#                 correlated_cols.append(c)\n",
    "#         groups.append(group)\n",
    "#         remaining_cols = [c for c in remaining_cols if c not in correlated_cols]\n",
    "    \n",
    "#     return groups\n",
    "\n",
    "# uses=[]\n",
    "# for k,v in nans_groups.items():\n",
    "#     if len(v)>1:\n",
    "#             Vs = nans_groups[k]\n",
    "#             grps= group_columns_by_correlation(df_train[Vs], threshold=0.8)\n",
    "#             use=reduce_group(grps)\n",
    "#             uses=uses+use\n",
    "#     else:\n",
    "#         uses=uses+v\n",
    "# #     print('####### NAN count =',k)\n",
    "# uses=uses+list(df_train.select_dtypes(include='category').columns)\n",
    "# df_train=df_train[uses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934b2d8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:16.819810Z",
     "iopub.status.busy": "2024-05-18T15:42:16.819551Z",
     "iopub.status.idle": "2024-05-18T15:42:17.243886Z",
     "shell.execute_reply": "2024-05-18T15:42:17.242865Z"
    },
    "papermill": {
     "duration": 0.432428,
     "end_time": "2024-05-18T15:42:17.246263",
     "exception": false,
     "start_time": "2024-05-18T15:42:16.813835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_store = {\n",
    "    \"df_base\": read_file(TEST_DIR / \"test_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(TEST_DIR / \"test_static_cb_0.parquet\"),\n",
    "        read_files(TEST_DIR / \"test_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n",
    "        read_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_other_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_person_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_deposit_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n",
    "        read_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n",
    "        read_files(TEST_DIR / \"test_person_2.parquet\", 2),\n",
    "        read_files(TEST_DIR / \"test_applprev_2.parquet\", 2),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f979f699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:17.257861Z",
     "iopub.status.busy": "2024-05-18T15:42:17.257567Z",
     "iopub.status.idle": "2024-05-18T15:42:17.946638Z",
     "shell.execute_reply": "2024-05-18T15:42:17.945717Z"
    },
    "papermill": {
     "duration": 0.696995,
     "end_time": "2024-05-18T15:42:17.948578",
     "exception": false,
     "start_time": "2024-05-18T15:42:17.251583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data shape:\t (10, 860)\n",
      "test data shape:\t (10, 860)\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.05 MB\n",
      "Decreased by 33.4%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = feature_eng(**data_store)\n",
    "print(\"test data shape:\\t\", df_test.shape)\n",
    "del data_store\n",
    "gc.collect()\n",
    "# df_test = df_test.select([col for col in df_train.columns if col != \"target\"])\n",
    "# print(\"train data shape:\\t\", df_train.shape)\n",
    "print(\"test data shape:\\t\", df_test.shape)\n",
    "\n",
    "# cat_cols = [col for col in cat_cols if col in df_test.columns]\n",
    "df_test, cat_cols = to_pandas(df_test, cat_cols)\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4729ed2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:17.960626Z",
     "iopub.status.busy": "2024-05-18T15:42:17.960341Z",
     "iopub.status.idle": "2024-05-18T15:42:18.000422Z",
     "shell.execute_reply": "2024-05-18T15:42:17.999494Z"
    },
    "papermill": {
     "duration": 0.048243,
     "end_time": "2024-05-18T15:42:18.002359",
     "exception": false,
     "start_time": "2024-05-18T15:42:17.954116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 400), 79)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test[train_cols + ['case_id']]\n",
    "df_test[cat_cols] = df_test[cat_cols].astype('str')\n",
    "\n",
    "df_test.shape, len(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "568e341b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:18.014878Z",
     "iopub.status.busy": "2024-05-18T15:42:18.014229Z",
     "iopub.status.idle": "2024-05-18T15:42:18.021336Z",
     "shell.execute_reply": "2024-05-18T15:42:18.020477Z"
    },
    "papermill": {
     "duration": 0.015473,
     "end_time": "2024-05-18T15:42:18.023303",
     "exception": false,
     "start_time": "2024-05-18T15:42:18.007830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VotingModel():\n",
    "    def __init__(self, estimators):\n",
    "        super().__init__()\n",
    "        self.estimators = estimators\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_preds = [estimator.predict(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        y_preds = [estimator.predict_proba(X) for estimator in self.estimators[:5]]\n",
    "        \n",
    "        X[cat_cols] = X[cat_cols].astype(\"category\")\n",
    "        y_preds += [estimator.predict_proba(X) for estimator in self.estimators[5:]]\n",
    "        \n",
    "        return np.mean(y_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e6f47c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:18.035314Z",
     "iopub.status.busy": "2024-05-18T15:42:18.035033Z",
     "iopub.status.idle": "2024-05-18T15:42:18.038796Z",
     "shell.execute_reply": "2024-05-18T15:42:18.038033Z"
    },
    "papermill": {
     "duration": 0.0118,
     "end_time": "2024-05-18T15:42:18.040569",
     "exception": false,
     "start_time": "2024-05-18T15:42:18.028769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = VotingModel(cbc+lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f2975d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:18.052300Z",
     "iopub.status.busy": "2024-05-18T15:42:18.052016Z",
     "iopub.status.idle": "2024-05-18T15:42:18.521849Z",
     "shell.execute_reply": "2024-05-18T15:42:18.520933Z"
    },
    "papermill": {
     "duration": 0.478035,
     "end_time": "2024-05-18T15:42:18.523929",
     "exception": false,
     "start_time": "2024-05-18T15:42:18.045894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57543</th>\n",
       "      <td>0.008524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57549</th>\n",
       "      <td>0.041243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57551</th>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57552</th>\n",
       "      <td>0.013109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57569</th>\n",
       "      <td>0.096083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57630</th>\n",
       "      <td>0.009015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57631</th>\n",
       "      <td>0.021138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57632</th>\n",
       "      <td>0.006781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57633</th>\n",
       "      <td>0.031769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57634</th>\n",
       "      <td>0.026031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score\n",
       "case_id          \n",
       "57543    0.008524\n",
       "57549    0.041243\n",
       "57551    0.002945\n",
       "57552    0.013109\n",
       "57569    0.096083\n",
       "57630    0.009015\n",
       "57631    0.021138\n",
       "57632    0.006781\n",
       "57633    0.031769\n",
       "57634    0.026031"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.set_index(\"case_id\")\n",
    "\n",
    "y_pred = pd.Series(model.predict_proba(df_test)[:,1], index=df_test.index)\n",
    "df_subm = pd.read_csv(ROOT / \"sample_submission.csv\")\n",
    "df_subm = df_subm.set_index(\"case_id\")\n",
    "\n",
    "df_subm[\"score\"] = y_pred\n",
    "\n",
    "df_subm.to_csv(\"submission.csv\")\n",
    "df_subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b84f7b02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:18.536797Z",
     "iopub.status.busy": "2024-05-18T15:42:18.536495Z",
     "iopub.status.idle": "2024-05-18T15:42:18.545824Z",
     "shell.execute_reply": "2024-05-18T15:42:18.544891Z"
    },
    "papermill": {
     "duration": 0.017882,
     "end_time": "2024-05-18T15:42:18.547772",
     "exception": false,
     "start_time": "2024-05-18T15:42:18.529890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check null:  False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57543</th>\n",
       "      <td>0.008524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57549</th>\n",
       "      <td>0.041243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57551</th>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57552</th>\n",
       "      <td>0.013109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57569</th>\n",
       "      <td>0.096083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score\n",
       "case_id          \n",
       "57543    0.008524\n",
       "57549    0.041243\n",
       "57551    0.002945\n",
       "57552    0.013109\n",
       "57569    0.096083"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Check null: \", df_subm[\"score\"].isnull().any())\n",
    "\n",
    "df_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e732810b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T15:42:18.560788Z",
     "iopub.status.busy": "2024-05-18T15:42:18.560508Z",
     "iopub.status.idle": "2024-05-18T15:42:18.565461Z",
     "shell.execute_reply": "2024-05-18T15:42:18.564760Z"
    },
    "papermill": {
     "duration": 0.013641,
     "end_time": "2024-05-18T15:42:18.567336",
     "exception": false,
     "start_time": "2024-05-18T15:42:18.553695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_subm.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 8589604,
     "datasetId": 4970565,
     "sourceId": 8451182,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 8488280,
     "datasetId": 4964813,
     "sourceId": 8355423,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 8489654,
     "datasetId": 4965854,
     "sourceId": 8356751,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.838777,
   "end_time": "2024-05-18T15:42:19.292913",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-18T15:41:59.454136",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
